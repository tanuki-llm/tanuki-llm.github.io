<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>日本語での対話・作文性能に力点を置いた大規模言語モデルの開発 – Tanuki Project</title>

  <!-- Tailwind CSS (v3 CDN) -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- Google Fonts（好みで変更可）-->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet" />
  <style>
    body { font-family: 'Inter', sans-serif; }
    /* hero 背景グラデーション */
    .hero-bg { background: radial-gradient(circle at 30% 30%, rgba(99,102,241,.25), rgba(236, 72, 153,.15) 60%, rgba(255,255,255,0)); }
  </style>
</head>
<body class="bg-gray-50 text-gray-900">

  <!-- ===== Hero ===== -->
  <header class="hero-bg pt-20 pb-28">
    <div class="max-w-5xl mx-auto px-6 text-center">
      <h1 class="text-4xl sm:text-5xl font-extrabold leading-tight">
        日本語での対話・作文性能に力点を置いた<br class="hidden sm:inline" />
        大規模言語モデルの開発
      </h1>
      <h2 class="mt-4 text-xl sm:text-2xl font-semibold text-indigo-600">
        －公募・公開型による LLM 開発プロジェクト “Tanuki” の報告－
      </h2>

      <!-- “タグ” のような小バッジ -->
      <a class="inline-block mt-6 px-4 py-1.5 rounded-full bg-slate-900 text-white text-sm font-medium hover:bg-slate-800 transition" href="https://tanuki-llm.github.io" target="_blank" rel="noopener">
        2025 Project Report
      </a>

      <!-- ボタン群 -->
      <nav class="flex flex-wrap justify-center gap-3 mt-10">
        <a class="px-4 py-2 rounded-md border border-gray-300 hover:bg-gray-100 transition text-sm font-medium" 
           href="https://github.com/matsuolab/tanuki" target="_blank" rel="noopener"> Code</a>

        <!-- 論文 PDF 等が用意できたらリンク先を差し替え -->
        <a class="px-4 py-2 rounded-md border border-gray-300 hover:bg-gray-100 transition text-sm font-medium" 
           href="#" target="_blank" rel="noopener"> Paper</a>

        <!-- 任意のブログや記事 -->
        <a class="px-4 py-2 rounded-md border border-gray-300 hover:bg-gray-100 transition text-sm font-medium" 
           href="#" target="_blank" rel="noopener"> Blog</a>

        <!-- NotebookLM などの要約ページ -->
        <a class="px-4 py-2 rounded-md border border-gray-300 hover:bg-gray-100 transition text-sm font-medium" 
           href="#" target="_blank" rel="noopener"> Summary</a>

        <a class="px-4 py-2 rounded-md border border-gray-300 hover:bg-gray-100 transition text-sm font-medium" 
           href="https://www.youtube.com/playlist?list=PLT07SIG9QbZzyqeK7AQMvvN0EqvJ7EvwP" target="_blank" rel="noopener"> Demo</a>
      </nav>
    </div>
  </header>

  <!-- ===== TL;DR ===== -->
  <section class="max-w-4xl mx-auto px-6 -mt-16">
    <div class="bg-white shadow-lg rounded-2xl p-8 ring-1 ring-slate-100">
      <h3 class="text-lg font-semibold">TL;DR</h3>
      <p class="mt-2 leading-relaxed">
        <strong>Tanuki</strong> は、公募型の貢献者コミュニティによって開発された日本語特化の LLM です。LLM、Tanuki-8B および
Tanuki-8x8B を開発し、Japanese MT-Bench (JMT-Bench) において、Tanuki 8Bは 10B級サイズのモデルを上回る性能を示し、Tanuki 8x8B は国内でフルスクラッチから開発されたモデル
の中でトップレベルの性能を達成しました。（2024年8月末時点） </p>
    </div>
  </section>

  <!-- ===== Demo Section ===== -->
  <section class="mt-24 mb-32">
    <div class="max-w-5xl mx-auto px-6 text-center">
      <h3 class="text-3xl font-bold">Tanuki in Action</h3>
      <p class="mt-4 text-gray-600">使い方やデモ（Coming soonn）をご覧ください。</p>

      <!-- YouTube playlist 埋め込み -->
      <div class="mt-10 aspect-video max-w-3xl mx-auto rounded-xl overflow-hidden shadow-lg">
        <iframe class="w-full h-full"
          src="https://www.youtube.com/embed/videoseries?list=PLT07SIG9QbZzyqeK7AQMvvN0EqvJ7EvwP"
          title="Tanuki demos" frameborder="0" allowfullscreen></iframe>
      </div>

      <!-- ポジティブ / ネガティブ例（任意）-->
      <div class="grid sm:grid-cols-2 gap-6 mt-14 text-left">
        <div class="p-6 bg-green-50 border border-green-200 rounded-xl">
          <h4 class="font-semibold mb-2">👍 改善点</h4>
          <p> 合成データを継続事前学習・事後学習に用いることにより，LLMの対話能力が向上することを実証した．   </p>
          <p class="mt-1">＊＊＊＊＊。</p>
          <p> アップサイクリングを使用し，学習途中のTanuki 8BをベースにMoE形式のTanuki 8x8Bを構築することで，損失の発散による学習失敗リスクと計算コストを抑えた学習を実現した．国内において，初めてのアップサイクリングに成功したLLM開発である．</p>
          <p class="mt-1">和＊＊＊＊＊。</p>        
        </div>
        <div class="p-6 bg-red-50 border border-red-200 rounded-xl">
          <h4 class="font-semibold mb-2">👎 制限事項</h4>
          <p>LLMの安全性に関しては確認が未検証/p>
          <p class="mt-1">＊＊＊＊＊。</p>
        </div>
      </div>
    </div>
  </section>

  <!-- ===== Footer ===== -->
  <footer class="bg-slate-900 text-gray-300 text-sm py-8">
    <div class="max-w-5xl mx-auto px-6 flex flex-col sm:flex-row justify-between items-center gap-4">
      <span>&copy; 2025 Tanuki LLM Project</span>
      <a class="hover:text-white underline-offset-4" href="https://github.com/matsuolab/tanuki" target="_blank" rel="noopener">
        GitHub Repository
      </a>
    </div>
  </footer>

</body>
</html>
